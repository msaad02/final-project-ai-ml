{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(fen):\n",
    "    data = re.split(\" \", fen)\n",
    "    rows= re.split(\"/\", data[0])\n",
    "    turn = data[1]\n",
    "    can_castle = data[2]\n",
    "    passant = data[3]\n",
    "    half_moves = data[4]\n",
    "    full_moves = data[5]\n",
    "    \n",
    "    bit_vector = np.zeros((13, 8, 8), dtype=np.uint8)\n",
    "    #what layer each piece is found on\n",
    "    piece_to_layer = {\n",
    "            'R': 1,\n",
    "            'N': 2,\n",
    "            'B': 3,\n",
    "            'Q': 4,\n",
    "            'K': 5,\n",
    "            'P': 6,\n",
    "            'p': 7,\n",
    "            'k': 8,\n",
    "            'q': 9,\n",
    "            'b': 10,\n",
    "            'n': 11,\n",
    "            'r': 12\n",
    "        }\n",
    "    #find each piece based on type\n",
    "    for r,value in enumerate(rows):\n",
    "        colum = 0\n",
    "        for piece in value:\n",
    "            if piece in piece_to_layer:\n",
    "                bit_vector[piece_to_layer[piece],r,colum] =1\n",
    "                colum += 1\n",
    "            else:\n",
    "                colum += int(piece)\n",
    "    \n",
    "    if turn.lower() == 'w':\n",
    "        bit_vector [0,7,4] =1\n",
    "    else:\n",
    "        bit_vector [0,0,4] =1\n",
    "        \n",
    "    #where each castle bit is located\n",
    "    castle ={\n",
    "        'k': (0,0),\n",
    "        'q': (0,7),\n",
    "        'K': (7,0),\n",
    "        'Q': (7,7),\n",
    "        }\n",
    "\n",
    "    for value in can_castle:\n",
    "        if value in castle:\n",
    "            bit_vector[0,castle[value][0],castle[value][1]] = 1\n",
    "    \n",
    "    #put en-passant square in the vector\n",
    "    if passant != '-':\n",
    "        bit_vector[0,  5 if (int(passant[1])-1 == 3) else 2 , ord(passant[0]) - 97,] = 1\n",
    "        \n",
    "    return bit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(vectorize(r'rnbqkb1r/ppp1pppp/3p4/3nP3/3P4/8/PPPK1PPP/RNBQ1BNR b kq - 1 4')[0])\n",
    "# print(vectorize(r'r3r1k1/pppq2bp/3pp1p1/3P4/2PpP3/6P1/PP1N2K1/R1BQR3 b - e3 0 19')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(df):\n",
    "    # Define the neural network architecture\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(800, 13, 8, 8)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    ## Get training and testing data\n",
    "    # Set the train-test split ratio\n",
    "    train_ratio = 0.8\n",
    "\n",
    "    # Shuffle the DataFrame\n",
    "    df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Calculate the number of samples for training\n",
    "    train_size = int(len(df_shuffled) * train_ratio)\n",
    "\n",
    "    # Split the DataFrame into training and testing sets\n",
    "    train_df = df_shuffled[:train_size]\n",
    "    test_df = df_shuffled[train_size:]\n",
    "\n",
    "    # Separate x and y columns\n",
    "    x_train, x_test = train_df.FEN, train_df.FEN\n",
    "    y_train, y_test = train_df.Evaluation, test_df.Evaluation\n",
    "\n",
    "    # x_train = np.asarray(x_train).astype('float32')\n",
    "    y_train = np.asarray(y_train).astype('float32')\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train, epochs=10, batch_size=1)\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "    # Print the evaluation metrics\n",
    "    print(f\"Test loss: {loss:.4f}\")\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/kaggleDataset/chessData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expects data frame with 1 column \"FEN\", and another \"Evaluation\"\n",
    "def train_test_split(df, random, train_size):\n",
    "    # Shuffle the DataFrame\n",
    "    df_shuffled = df.sample(frac=1, random_state=random).reset_index(drop=True)\n",
    "\n",
    "    # Calculate the number of samples for training\n",
    "    train_size = int(len(df_shuffled) * train_size)\n",
    "\n",
    "    # Split the DataFrame into training and testing sets\n",
    "    train_df = df_shuffled[:train_size]\n",
    "    test_df = df_shuffled[train_size:]\n",
    "\n",
    "    # Separate x and y columns\n",
    "    x_train, x_test = train_df.FEN, train_df.FEN\n",
    "    y_train, y_test = train_df.Evaluation, test_df.Evaluation\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train_test_split() got an unexpected keyword argument 'random_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(df, random_state\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, train_size \u001b[39m=\u001b[39;49m \u001b[39m.75\u001b[39;49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: train_test_split() got an unexpected keyword argument 'random_state'"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df, random=0, train_size = .75)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the FEN strings\n",
    "\n",
    "Getting the vectorized version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEN</th>\n",
       "      <th>Evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[1, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>+56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[1, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>+52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[1, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>[[[1, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>+135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>[[[1, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>+84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[[[1, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>+116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>[[[1, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>+43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   FEN Evaluation\n",
       "0    [[[1, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0,...        -10\n",
       "1    [[[1, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0,...        +56\n",
       "2    [[[1, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0,...         -9\n",
       "3    [[[1, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0,...        +52\n",
       "4    [[[1, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0,...        -26\n",
       "..                                                 ...        ...\n",
       "995  [[[1, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0,...        +20\n",
       "996  [[[1, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0,...       +135\n",
       "997  [[[1, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0,...        +84\n",
       "998  [[[1, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0,...       +116\n",
       "999  [[[1, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0,...        +43\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcopy = df.copy().head(1000)\n",
    "\n",
    "vectorized = dfcopy.FEN.apply(vectorize)  # type: ignore\n",
    "dfcopy.FEN = vectorized\n",
    "dfcopy\n",
    "\n",
    "# Save to CSV?\n",
    "# dfcopy.to_csv('../data/createdData/vectorized.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Weird Evaluation Scores\n",
    "\n",
    "Some are like \"#+6\", or even stranger like \"\\ufeff23\". Want them all to be +/- integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to handle weird cases in Evaluation such as \"#+6\", or \"\\ufeff23\"\n",
    "def parse_evaluation(value):\n",
    "    if isinstance(value, str):\n",
    "        value = re.sub(r'[^0-9+\\-]', '', value)  # Remove anything that's not a digit or '+' or '-'\n",
    "        return int(value.replace('-', '')) * (-1 if '-' in value else 1)\n",
    "    return value\n",
    "\n",
    "# Apply the parsing function to the 'Evaluation' column\n",
    "dfcopy['Evaluation'] =  dfcopy['Evaluation'].apply(parse_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dfcopy.Evaluation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try making the neural network\n",
    "\n",
    "Hasn't worked so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [[[1, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0,...\n",
       "1      [[[1, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0,...\n",
       "2      [[[1, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0,...\n",
       "3      [[[1, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0,...\n",
       "4      [[[1, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0,...\n",
       "                             ...                        \n",
       "995    [[[1, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0,...\n",
       "996    [[[1, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0,...\n",
       "997    [[[1, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0,...\n",
       "998    [[[1, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0,...\n",
       "999    [[[1, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0,...\n",
       "Name: FEN, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Issue is with the vectorized FEN strings. They aren't converting nicely. Try different things.\n",
    "dfcopy.FEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_neural_network(dfcopy)\n",
      "Cell \u001b[1;32mIn[10], line 38\u001b[0m, in \u001b[0;36mtrain_neural_network\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     34\u001b[0m y_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(y_train)\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     40\u001b[0m \u001b[39m# Evaluate the model on the test data\u001b[39;00m\n\u001b[0;32m     41\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(x_test, y_test)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "train_neural_network(dfcopy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
